{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HHO3U7vB9Tgg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize():\n",
        "    X = np.array([[0.05, 0.10]])      # Inputs\n",
        "    W1 = np.array([[0.15, 0.20], [0.25, 0.30]])      # Weights to calculate outputs for hidden layer 1\n",
        "    b1 = 0.35      # Bias for hidden layer 1\n",
        "    W2 = np.array([[0.40, 0.45], [0.50, 0.55]])     # Weights to calculate outputs for output layer\n",
        "    b2 = 0.60      # Bias for output layer\n",
        "    Y = np.array([[0.01, 0.99]])      # Desired output\n",
        "    learning_rate = 0.5\n",
        "    no_of_iter = int(100)\n",
        "    return X, W1, b1, W2, b2, Y, learning_rate, no_of_iter\n"
      ],
      "metadata": {
        "id": "bUJj2Bjv_WMm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(X, W1, b1, W2, b2):\n",
        "    Z1 = np.dot(X, W1.T) + b1\n",
        "    A1 = 1 / (1 + np.exp(-Z1))\n",
        "    Z2 = np.dot(A1, W2.T) + b2\n",
        "    A2 = 1 / (1 + np.exp(-Z2))\n",
        "    return A1, A2"
      ],
      "metadata": {
        "id": "ZLBVpxQ3_bgj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def back_propagation(X, W1, W2, Y, A1, A2, learning_rate):\n",
        "    dEdA2 = A2 - Y\n",
        "    dA2dZ2 = np.multiply(A2, 1 - A2)\n",
        "    dZ2dW2 = A1\n",
        "    dEdW2 = dEdA2 * dA2dZ2 * dZ2dW2\n",
        "    W2_adj = W2 - learning_rate * dEdW2.T\n",
        "\n",
        "    dZ2dA1 = W2.T\n",
        "    dA1dZ1 = np.multiply(A1, 1 - A1)\n",
        "    dZ1dW1 = X\n",
        "    dEdW1 = dEdA2 * dA2dZ2 * dZ2dA1 * dA1dZ1 * dZ1dW1\n",
        "    W1_adj = W1 - learning_rate * dEdW1.T\n",
        "\n",
        "    return W1_adj, W2_adj\n"
      ],
      "metadata": {
        "id": "ZODDMgur_gAy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_neural_network():\n",
        "    X, W1, b1, W2, b2, Y, learning_rate, no_of_iter = initialize()\n",
        "\n",
        "    for iter in range(no_of_iter):\n",
        "        A1, A2 = forward_pass(X, W1, b1, W2, b2)\n",
        "        W1, W2 = back_propagation(X, W1, W2, Y, A1, A2, learning_rate)\n",
        "\n",
        "    print('W1 = {}\\n\\n W2 = {}\\n\\n Output = {}\\n Desired output = {}'.format(W1, W2, A2, Y))\n"
      ],
      "metadata": {
        "id": "wsMtSC8t_jlY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Increase the number of iterations (epochs)\n",
        "no_of_iter = 10000\n",
        "\n",
        "train_neural_network()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl4nCWLj_peT",
        "outputId": "5fb29fa6-36fa-4afa-e72d-7d394c996d53"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1 = [[0.1813 0.2291]\n",
            " [0.2703 0.3216]]\n",
            "\n",
            " W2 = [[-1.819  -1.769 ]\n",
            " [ 1.1239  1.1739]]\n",
            "\n",
            " Output = [[0.1781 0.8771]]\n",
            " Desired output = [[0.01 0.99]]\n"
          ]
        }
      ]
    }
  ]
}